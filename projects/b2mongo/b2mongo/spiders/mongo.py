import scrapy
from   scrapy.loader import ItemLoader
from   b2mongo.items import BookItem


class MongoSpider(scrapy.Spider):
    name            =  "mongo"
    allowed_domains = ["books.toscrape.com"]
    start_urls      = ["https://books.toscrape.com/"]

    def __init__(self, category=None, max_pages=None, *args, **kwargs):
        super(MongoSpider, self).__init__(*args, **kwargs)
        self.category_filter = category
        self.max_pages       = int(max_pages) if max_pages else None
        self.pages_scraped   = 0
        self.books_scraped   = 0
        self.logger.info(f"Le spider d√©marre üöÄ üöÄ üöÄ")
        if self.category_filter:
            self.logger.info(f"üîç Filtrage cat√©goriel {self.category_filter}")
        if self.max_pages:
            self.logger.info(f"Il y a {self.max_pages} pages")

    def parse(self, response):
        """Parser la page d'accueil et extrait les cat√©gories"""
        # Extraire toutes les cat√©gories du menu lat√©ral
        categories = response.xpath('//div[@class="side_categories"]//ul/li/ul/li/a')
        
        self.logger.info(f"üìö {len(categories)} cat√©gories trouv√©es")
        
        for category in categories:
            category_name = category.xpath('./text()').get().strip()
            category_url  = category.xpath('./@href').get()
            
            # Filtrer par cat√©gorie si demand√©
            if self.category_filter and self.category_filter.lower() not in category_name.lower():
                continue
            
            self.logger.info(f"üìñ Scraping de la  cat√©gorie {category_name}")
            
            yield response.follow(
                category_url,
                callback = self.parse_category,
                meta     = {'category': category_name}
            )
    
    def parse_category(self, response):
        """Parse une page de cat√©gorie et extrait les livres"""
        category = response.meta['category']
        books    = response.xpath('//article[@class="product_pod"]')
        
        self.logger.info(f"üìï Il y a {len(books)} livres trouv√©s dans {category}")
        
        # Extraire chaque livre
        for book in books:
            book_url = book.xpath('.//h3/a/@href').get()
            
            yield response.follow(
                book_url,
                callback = self.parse_book,
                meta     = {'category': category}
            )
        
        # G√©rer la pagination
        next_page = response.xpath('//li[@class="next"]/a/@href').get()
        
        if next_page:
            # V√©rifier la limite de pages
            if self.max_pages and self.pages_scraped >= self.max_pages:
                self.logger.info(f"‚ö†Ô∏è La limite de {self.max_pages} pages est atteinte")
                return
            
            self.pages_scraped += 1
            self.logger.info(f"‚û°Ô∏è Page suivante")   # {next_page}
            
            yield response.follow(
                next_page,
                callback = self.parse_category,
                meta     = {'category': category}
            )
        else:
            self.logger.info(f"‚úÖ La collection {category} est compl√®te")
    
    def parse_book(self, response):
        """Parse les d√©tails d'un livre"""
        loader = ItemLoader(item = BookItem(), response = response)
        
        # Informations de base
        loader.add_xpath('title'   , '//div[@class="product_main"]/h1/text()')
        loader.add_value('url'     , response.url)
        loader.add_value('category', response.meta['category'])
        
        # Tableau d'informations produit
        loader.add_xpath('upc'           , '//table[@class="table table-striped"]//tr[1]/td/text()')
        loader.add_xpath('price_excl_tax', '//table[@class="table table-striped"]//tr[3]/td/text()')
        loader.add_xpath('price_incl_tax', '//table[@class="table table-striped"]//tr[4]/td/text()')
        loader.add_xpath('tax'           , '//table[@class="table table-striped"]//tr[5]/td/text()')
        loader.add_xpath('availability'  , '//table[@class="table table-striped"]//tr[6]/td/text()')
        loader.add_xpath('number_of_reviews', '//table[@class="table table-striped"]//tr[7]/td/text()')
        
        # Rating (extraire la classe CSS)
        rating_class = response.xpath('//p[contains(@class, "star-rating")]/@class').get()
        if rating_class:
            rating = rating_class.split()[-1]  # Ex: "star-rating Three" -> "Three"
            loader.add_value('rating', rating)
        
        loader.add_xpath('description', '//div[@id="product_description"]/following-sibling::p/text()')
        
        image_url = response.xpath('//div[@class="item active"]//img/@src').get()
        if image_url:
            # Convertir l'URL relative en absolue et l'ajouter comme valeur unique
            absolute_url = response.urljoin(image_url)
            loader.add_value('image_url', absolute_url)
        
        self.books_scraped += 1
        
        if self.books_scraped % 50 == 0:
            self.logger.info(f"{self.books_scraped} livres scrap√©s")
        
        yield loader.load_item()