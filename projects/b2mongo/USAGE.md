<div align="center">

![Scrapy](https://img.shields.io/badge/Scrapy-Web_Scraping-5E8862?style=flat&logo=scrapy&logoColor=white)


</div>

## **Le lancement du Spider**
### **Les prÃ©requis**
MongoDB dÃ©marrÃ© sur localhost:27017â€‹
L'environnement virtuel est activÃ© avec scrapy et pymongo
Le dossier `images/` est crÃ©Ã© (pour `IMAGES_STORE`)
## **La structure d'exÃ©cution**
```sh
mongoBooks/          # Dossier projet
â”œâ”€â”€ mongo.py         # Spider principal
â”œâ”€â”€ items.py
â”œâ”€â”€ pipelines.py
â”œâ”€â”€ queries.py
â”œâ”€â”€ scrapy.cfg       # OU settings.py
â””â”€â”€ images/          # CrÃ©er ce dossier
```
### 1. Les commandes de base
Spider complet (toutes catÃ©gories)
```sh
scrapy crawl mongo
RÃ©sultat attendu : ~1000 livres scrapÃ©s, stockÃ©s en books_db.booksâ€‹

Filtre par catÃ©gorie
bash
# Seulement "Travel"
scrapy crawl mongo -a category=Travel

# Seulement "Python" (insensible Ã  la casse)
scrapy crawl mongo -a category=python
Limite de pages par catÃ©gorie
bash
# Max 3 pages/catÃ©gorie (plus rapide pour tests)
scrapy crawl mongo -a max_pages=3

# CatÃ©gorie + limite
scrapy crawl mongo -a category=Travel -a max_pages=2
```
### 2. Les logs de suiviâ€‹
Le spider affiche en temps rÃ©el :
```txt
ðŸš€ Le spider dÃ©marre
ðŸ“š 21 catÃ©gories trouvÃ©es
ðŸ“– Scraping de la catÃ©gorie Travel
ðŸ“• 20 livres trouvÃ©s dans Travel
âž¡ï¸ Page suivante (page 2/50)
50 livres scrapÃ©s
âœ… La collection Travel est complÃ¨te
âœ… 987 livres stockÃ©s
```
### 3. VÃ©rification MongoDB
```sh
# Ouvrir MongoDB shell
mongosh

# VÃ©rifier les donnÃ©es
use books_db
db.books.countDocuments()           # â†’ ~1000
db.books.findOne()                 # Premier livre
db.books.distinct("category")      # Liste catÃ©gories
```
Collections crÃ©Ã©es automatiquement :â€‹
books : documents BookItem (index upc unique)
Index : upc, category, rating
### 4. Les images tÃ©lÃ©chargÃ©es
Les couvertures sont dans ./images/full/ :
```txt
images/
â””â”€â”€ full/
    â”œâ”€â”€ 9780132354526.jpg
    â”œâ”€â”€ 9780440237220.jpg
    â””â”€â”€ ...
```
Champs enrichis :â€‹
image_url : URL originale
image_path : "full/9780132354526.jpg"
### 5. Analyses avec queries.py
```sh
python queries.py
```
Sortie console :â€‹
```txt
Total livres: 1000
# Top 10 rating 5
"It's Only the Himalayas" - 53.99Â£
# CatÃ©gories
Counter({'Default': 1000, 'Travel': 50, ...})
# Prix moyen/catÃ©gorie
Travel: 45.23Â£ (50 livres)
Poetry: 38.99Â£ (45 livres)
# Stats globales
{'total': 1000, 'avg_price': 32.85, 'max_price': 59.99, 'min_price': 9.99}
```
### âš™ï¸ 6. settings.py obligatoiresâ€‹
Ajouter dans ton settings.py (ou crÃ©er si absent) :
```py
# Pipelines (ordre important !)
ITEM_PIPELINES = {
    'mongoBooks.pipelines.MongoDBPipeline'  : 300,
    'scrapy.pipelines.images.ImagesPipeline': 400,
}

# MongoDB
MONGO_URI = 'mongodb://localhost:27017/'
MONGO_DATABASE = 'books_db'

# Images
IMAGES_STORE = 'images'

# Respect du site (Ã©thique)
DOWNLOAD_DELAY = 1.0
AUTOTHROTTLE_ENABLED = True
CONCURRENT_REQUESTS = 8
```
### 7. Modes de test rapides
Objectif	Commande	DurÃ©e estimÃ©e	Livres
Test rapide	scrapy crawl mongo -a max_pages=1	2min	~20
Une catÃ©gorie	scrapy crawl mongo -a category=Travel	5min	~50
Complet	scrapy crawl mongo	15min	~1000
Debug	scrapy crawl mongo -s LOG_LEVEL=DEBUG	-	-
### 8. Exports avancÃ©s
JSON pour notebooks
```sh
scrapy crawl mongo -o books.json
````
CSV (Pandas-ready)
```sh
scrapy crawl mongo -o books.csv
```
Via MongoDB â†’ Pandas
```py
# Dans un notebook
from pymongo import MongoClient
import pandas as pd

client = MongoClient()
df = pd.DataFrame(list(client.books_db.books.find()))
df.to_csv('books_clean.csv', index=False)
```
### 9. Commandes utiles
```sh
# Shell Scrapy (tester XPath)
scrapy shell 'https://books.toscrape.com/'

# Voir structure site
scrapy view https://books.toscrape.com/

# Logs dÃ©taillÃ©s
scrapy crawl mongo -s LOG_LEVEL=INFO

# Stats du spider
scrapy crawl mongo -s LOGSTATS=True
```
## **La structure de BookItems**
```mermaid
graph LR
    A[BookItem] --> B[Titre<br/>str]
    A --> C[URL<br/>str]
    A --> D[UPC<br/>str ðŸ”‘]
    A --> E[prix_excl_tax<br/>float âœ“]
    A --> F[prix_incl_tax<br/>float âœ“]
    A --> G[tax<br/>float âœ“]
    A --> H[availability<br/>int âœ“]
    A --> I[rating<br/>1-5 int âœ“]
    A --> J[category<br/>str]
    A --> K[description<br/>HTML nettoyÃ©]
    A --> L[number_of_reviews<br/>int]
    A --> M[image_url<br/>str]
    A --> N[image_path<br/>local âœ“]
    
    E -.->|clean_price<br/>Â£â†’float| O[MapCompose]
    H -.->|clean_stock<br/>regexâ†’int| O
    I -.->|rating_to_number<br/>Oneâ†’1| O
    K -.->|remove_tags+Join<br/>'\n'| O
    
    style D fill:#ffcdd2
    style O fill:#fff9c4
```